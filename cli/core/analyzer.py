#!/usr/bin/env python3
"""
ì½”ë“œ ë¶„ì„ì„ ë‹´ë‹¹í•˜ëŠ” CoeAnalyzer í´ë˜ìŠ¤
íŒŒì¼ ë¶„ì„, LLM ê¸°ë°˜ ì‹¬í™” ë¶„ì„, ê²°ê³¼ í‘œì‹œ ë“±ì˜ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.
"""

import sys
import os
from typing import Dict, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

from actions.file_manager import FileManager
from llm.service import LLMService
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.tree import Tree
from rich.markdown import Markdown
from .debug_manager import DebugManager


class CoeAnalyzer:
    def __init__(self):
        self.file_manager = FileManager()
        self.llm_service = LLMService()
        self.console = Console()

    def analyze_files(self, file_paths: List[str], use_llm: bool = True) -> Dict:
        """íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜"""
        analysis_results = {
            'files': {},
            'summary': {},
            'call_graph': {},
            'file_categories': {}
        }
        
        # íŒŒì¼ë“¤ ì¶”ê°€ ë° ê¸°ë³¸ ë¶„ì„
        self.console.print("[bold blue]ğŸ“ íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...[/bold blue]")
        
        for file_path in file_paths:
            if os.path.exists(file_path):
                result = self.file_manager.add_single_file(file_path)
                if result['analysis']:
                    analysis_results['files'][file_path] = {
                        'file_type': result['file_type'],
                        'basic_analysis': result['analysis'],
                        'llm_analysis': None
                    }
        
        # LLM ê¸°ë°˜ ë¶„ì„
        if use_llm and analysis_results['files']:
            self.console.print("[bold blue] LLMì„ í†µí•œ ì‹¬í™” ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...[/bold blue]")
            llm_analysis = self._perform_llm_analysis(analysis_results['files'])
            
            # LLM ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©
            for file_path, llm_result in llm_analysis.items():
                if file_path in analysis_results['files']:
                    analysis_results['files'][file_path]['llm_analysis'] = llm_result
            
            # ì „ì²´ ìš”ì•½ ìƒì„±
            analysis_results['summary'] = self._generate_summary(analysis_results['files'])
            analysis_results['call_graph'] = self._extract_call_relationships(analysis_results['files'])
            analysis_results['file_categories'] = self._categorize_files(analysis_results['files'])
        
        return analysis_results

    def _perform_llm_analysis(self, files_data: Dict) -> Dict:
        """LLMì„ í†µí•œ íŒŒì¼ ë¶„ì„"""
        llm_results = {}
        
        DebugManager.llm(f"_perform_llm_analysis ì‹œì‘, íŒŒì¼ ìˆ˜: {len(files_data)}")
        
        for file_path, file_info in files_data.items():
            try:
                DebugManager.llm(f"íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path}")
                
                # íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                content = self.file_manager.files.get(file_path, "")
                DebugManager.llm(f"íŒŒì¼ ë‚´ìš© ê¸¸ì´: {len(content)}")

                if not content:
                    DebugManager.llm(f"íŒŒì¼ ë‚´ìš©ì´ ë¹„ì–´ìˆì–´ ê±´ë„ˆëœ€: {file_path}")
                    continue

                # LLM ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                analysis_prompt = self._build_analysis_prompt(file_path, file_info, content)
                DebugManager.llm(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(analysis_prompt)}")
                
                # LLM í˜¸ì¶œ
                messages = [
                    {"role": "system", "content": "You are a code analysis expert. Analyze the given file and provide structured insights."},
                    {"role": "user", "content": analysis_prompt}
                ]
                
                DebugManager.llm("LLM í˜¸ì¶œ ì‹œì‘")
                response = self.llm_service.chat_completion(messages)
                
                if response and "choices" in response:
                    llm_content = response["choices"][0]["message"]["content"]
                    DebugManager.llm(f"LLM ì‘ë‹µ ê¸¸ì´: {len(llm_content)}")
                    DebugManager.llm(f"LLM ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {llm_content[:200]}...")
                    
                    parsed_result = self._parse_llm_response(llm_content)
                    DebugManager.llm(f"íŒŒì‹± ê²°ê³¼ í‚¤ë“¤: {list(parsed_result.keys()) if isinstance(parsed_result, dict) else 'not dict'}")
                    
                    llm_results[file_path] = parsed_result
                else:
                    DebugManager.llm("LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŒ ë˜ëŠ” í˜•ì‹ ì˜¤ë¥˜")
                
            except Exception as e:
                self.console.print(f"[red]LLM ë¶„ì„ ì‹¤íŒ¨ ({file_path}): {e}[/red]")
                import traceback
                self.console.print(f"[dim]{traceback.format_exc()}[/dim]")
                continue
        
        DebugManager.llm(f"_perform_llm_analysis ì™„ë£Œ, ê²°ê³¼ ìˆ˜: {len(llm_results)}")
        return llm_results

    def _build_analysis_prompt(self, file_path: str, file_info: Dict, content: str) -> str:
        """íŒŒì¼ íƒ€ì…ë³„ íŠ¹í™”ëœ LLM ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        file_type = file_info.get('file_type', 'unknown')
        
        # íŒŒì¼ íƒ€ì…ë³„ ì „ìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        try:
            if file_type == 'c_file' or file_path.endswith('.c'):
                from prompts.c_file_prompt import get_c_file_analysis_prompt
                return get_c_file_analysis_prompt(file_path, file_info, content)
            
            elif file_type == 'xml_file' or file_path.lower().endswith('.xml'):
                from prompts.xml_file_prompt import get_xml_file_analysis_prompt
                return get_xml_file_analysis_prompt(file_path, file_info, content)
            
            elif file_type == 'sql_file' or file_path.endswith('.sql'):
                from prompts.sql_file_prompt import get_sql_file_analysis_prompt
                return get_sql_file_analysis_prompt(file_path, file_info, content)
            
            else:
                # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
                from prompts.generic_file_prompt import get_generic_file_analysis_prompt
                return get_generic_file_analysis_prompt(file_path, file_info, content)
                
        except ImportError as e:
            self.console.print(f"[red]í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}[/red]")
            # fallback to basic prompt
            return self._get_fallback_prompt(file_path, file_info, content)
    
    def _get_fallback_prompt(self, file_path: str, file_info: Dict, content: str) -> str:
        """í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ fallback í”„ë¡¬í”„íŠ¸"""
        basic_analysis = file_info.get('basic_analysis', {})
        file_type = file_info.get('file_type', 'unknown')
        
        return f"""íŒŒì¼ ë¶„ì„ ìš”ì²­ (Fallback):

íŒŒì¼ ê²½ë¡œ: {file_path}
íŒŒì¼ íƒ€ì…: {file_type}

ê¸°ë³¸ ë¶„ì„ ê²°ê³¼:
{str(basic_analysis)}

íŒŒì¼ ë‚´ìš©:
```
{content[:3000]}{'...' if len(content) > 3000 else ''}
```

ë‹¤ìŒ í•­ëª©ë“¤ì„ JSON í˜•íƒœë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. purpose: íŒŒì¼ì˜ ì£¼ìš” ëª©ì ê³¼ ì—­í• 
2. key_functions: ì£¼ìš” í•¨ìˆ˜ë“¤

JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”."""

    def _parse_llm_response(self, llm_content: str) -> Dict:
        """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜"""
        try:
            import json
            # JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
            if '```json' in llm_content:
                start = llm_content.find('```json') + 7
                end = llm_content.find('```', start)
                json_str = llm_content[start:end].strip()
            elif llm_content.strip().startswith('{'):
                json_str = llm_content.strip()
            else:
                # JSONì´ ì•„ë‹Œ ê²½ìš° ê¸°ë³¸ êµ¬ì¡°ë¡œ ë³€í™˜
                return {
                    'purpose': 'LLM ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨',
                    'raw_response': llm_content
                }
            
            return json.loads(json_str)
        except Exception as e:
            return {
                'purpose': 'LLM ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨',
                'error': str(e),
                'raw_response': llm_content
            }

    def _generate_summary(self, files_data: Dict) -> Dict:
        """ì „ì²´ íŒŒì¼ë“¤ì˜ ìš”ì•½ ìƒì„±"""
        summary = {
            'total_files': len(files_data),
            'file_types': {},
            'common_patterns': []
        }
        
        # íŒŒì¼ íƒ€ì…ë³„ í†µê³„
        for file_path, file_info in files_data.items():
            file_type = file_info.get('file_type', 'unknown')
            if file_type not in summary['file_types']:
                summary['file_types'][file_type] = 0
            summary['file_types'][file_type] += 1
        
        
        return summary

    def _extract_call_relationships(self, files_data: Dict) -> Dict:
        """í˜¸ì¶œ ê´€ê³„ ë¶„ì„"""
        call_graph = {}
        
        for file_path, file_info in files_data.items():
            llm_analysis = file_info.get('llm_analysis', {})
            if llm_analysis and 'call_patterns' in llm_analysis:
                call_graph[file_path] = llm_analysis['call_patterns']
        
        return call_graph

    def _categorize_files(self, files_data: Dict) -> Dict:
        """íŒŒì¼ë“¤ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        categories = {
            'controller': [],
            'utils': [],
            'service': [],
            'sql': [],
            'config': [],
            'ui': [],
            'other': []
        }
        
        for file_path, file_info in files_data.items():
            llm_analysis = file_info.get('llm_analysis', {})
            file_type = file_info.get('file_type', 'unknown')
            
            # íŒŒì¼ëª…ê³¼ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ê²°ì •
            filename = os.path.basename(file_path).lower()
            
            if file_type == 'sql_file' or filename.endswith('.sql'):
                categories['sql'].append(file_path)
            elif any(keyword in filename for keyword in ['main', 'controller', 'ctrl']):
                categories['controller'].append(file_path)
            elif any(keyword in filename for keyword in ['util', 'helper', 'tool']):
                categories['utils'].append(file_path)
            elif any(keyword in filename for keyword in ['service', 'svc']):
                categories['service'].append(file_path)
            elif any(keyword in filename for keyword in ['config', 'setting']):
                categories['config'].append(file_path)
            elif file_type == 'xml_file' or filename.endswith('.xml'):
                categories['ui'].append(file_path)
            else:
                categories['other'].append(file_path)
        
        return categories

    def display_analysis_results(self, results: Dict):
        """ë¶„ì„ ê²°ê³¼ë¥¼ Rich UIë¡œ í‘œì‹œ"""
        self.console.print("\n[bold green]ğŸ¯ ì½”ë“œ êµ¬ì¡° ë¶„ì„ ê²°ê³¼[/bold green]")
        
        # 1. ì „ì²´ ìš”ì•½
        self._display_summary(results['summary'])
        
        # 2. íŒŒì¼ ì¹´í…Œê³ ë¦¬
        self._display_file_categories(results['file_categories'])
        
        # 3. íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„
        self._display_detailed_analysis(results['files'])
        
        # 4. í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„
        if results['call_graph']:
            self._display_call_graph(results['call_graph'])

    def _display_summary(self, summary: Dict):
        """ì „ì²´ ìš”ì•½ í‘œì‹œ"""
        if not summary:
            return
            
        # ìš”ì•½ íŒ¨ë„
        summary_text = f"ë¶„ì„ëœ íŒŒì¼ ìˆ˜: {summary.get('total_files', 0)}ê°œ\n"
        
        file_types = summary.get('file_types', {})
        if file_types:
            summary_text += "\níŒŒì¼ íƒ€ì…ë³„ ë¶„í¬:\n"
            for file_type, count in file_types.items():
                summary_text += f"  â€¢ {file_type}: {count}ê°œ\n"
        
        
        panel = Panel(
            summary_text.strip(),
            title="ğŸ“Š ì „ì²´ ìš”ì•½",
            border_style="blue"       
        )
        self.console.print(panel)

    def _display_file_categories(self, categories: Dict):
        """íŒŒì¼ ì¹´í…Œê³ ë¦¬ í‘œì‹œ"""
        if not categories:
            return
            
        tree = Tree("ğŸ“ íŒŒì¼ ì¹´í…Œê³ ë¦¬")
        
        for category, files in categories.items():
            if files:
                category_node = tree.add(f"[bold]{category.upper()}[/bold] ({len(files)}ê°œ)")
                for file_path in files:
                    filename = os.path.basename(file_path)
                    category_node.add(f"ğŸ“„ {filename}")
        
        self.console.print(tree)
    
    def _create_file_type_tables(self, llm_analysis: Dict, file_path: str) -> List:
        """íŒŒì¼ íƒ€ì…ë³„ íŠ¹í™” í…Œì´ë¸” ìƒì„±"""
        tables = []
        
        # C íŒŒì¼ íŠ¹í™” í…Œì´ë¸”ë“¤
        if file_path.endswith('.c'):
            # IO Formatter ë¶„ì„ í…Œì´ë¸”
            if 'io_formatter_analysis' in llm_analysis:
                io_formatter = llm_analysis['io_formatter_analysis']
                
                # í†µí•©ëœ IO Formatter í…Œì´ë¸”
                has_input = 'input_structure' in io_formatter and io_formatter['input_structure'].get('key_fields')
                has_output = 'output_structure' in io_formatter and io_formatter['output_structure'].get('key_fields')
                
                if has_input or has_output:
                    formatter_table = Table(title="ğŸ“‹ IO Formatter", show_header=True, header_style="bold blue")
                    formatter_table.add_column("êµ¬ë¶„")
                    formatter_table.add_column("í•„ë“œëª…")
                    formatter_table.add_column("íƒ€ì…")
                    formatter_table.add_column("Nullable")
                    formatter_table.add_column("ì„¤ëª…")
                    
                    # ì…ë ¥ í•„ë“œë“¤ ì¶”ê°€
                    if has_input:
                        for field in io_formatter['input_structure']['key_fields']:
                            nullable_text = "O" if field.get('nullable', False) else "X"
                            formatter_table.add_row(
                                "ğŸ“¥ ì…ë ¥",
                                field.get('name', 'N/A'),
                                field.get('type', 'N/A'),
                                nullable_text,
                                field.get('description', 'N/A')
                            )
                    
                    # ì¶œë ¥ í•„ë“œë“¤ ì¶”ê°€
                    if has_output:
                        for field in io_formatter['output_structure']['key_fields']:
                            formatter_table.add_row(
                                "ğŸ“¤ ì¶œë ¥",
                                field.get('name', 'N/A'),
                                field.get('type', 'N/A'),
                                "-",  # ì¶œë ¥ì€ nullable í‘œì‹œ ì•ˆí•¨
                                field.get('description', 'N/A')
                            )
                    
                    tables.append(formatter_table)
            
            # DBIO í˜¸ì¶œ ë¶„ì„ í…Œì´ë¸”
            if 'dbio_analysis' in llm_analysis and llm_analysis['dbio_analysis'].get('dbio_calls'):
                dbio_table = Table(title="ğŸ—„ï¸ DBIO í˜¸ì¶œ ë¶„ì„", show_header=True, header_style="bold magenta")
                dbio_table.add_column("í•¨ìˆ˜ëª…")
                dbio_table.add_column("ëª©ì ")
                dbio_table.add_column("ì…ë ¥ ë°ì´í„°")
                dbio_table.add_column("ì¶œë ¥ ë°ì´í„°")
                
                for dbio_call in llm_analysis['dbio_analysis']['dbio_calls']:
                    dbio_table.add_row(
                        dbio_call.get('function_name', 'N/A'),
                        dbio_call.get('purpose', 'N/A'),
                        dbio_call.get('input_data', 'N/A'),
                        dbio_call.get('output_data', 'N/A')
                    )
                tables.append(dbio_table)
                
        # XML íŒŒì¼ íŠ¹í™” í…Œì´ë¸”ë“¤
        elif file_path.lower().endswith('.xml'):
            # TrxCode ë¶„ì„ í…Œì´ë¸”
            if 'trxcode_analysis' in llm_analysis and llm_analysis['trxcode_analysis'].get('trx_codes'):
                trx_table = Table(title="ğŸ”„ TrxCode ë¶„ì„", show_header=True, header_style="bold purple")
                trx_table.add_column("TrxCode")
                trx_table.add_column("í•¨ìˆ˜ëª…")
                trx_table.add_column("ëª©ì ")
                trx_table.add_column("í˜¸ì¶œ ì‹œì ")
                trx_table.add_column("ì„¤ëª…")
                
                for trx in llm_analysis['trxcode_analysis']['trx_codes']:
                    trx_table.add_row(
                        trx.get('code', 'N/A'),
                        trx.get('function_name', 'N/A'),
                        trx.get('purpose', 'N/A'),
                        trx.get('trigger', 'N/A'),
                        trx.get('description', 'N/A')
                    )
                tables.append(trx_table)
            
            # ë°ì´í„° íë¦„ í…Œì´ë¸” (XMLì€ required/optionalë¡œ êµ¬ë¶„)
            if 'data_flow' in llm_analysis:
                data_flow = llm_analysis['data_flow']
                
                # ì…ë ¥ í•„ë“œ í…Œì´ë¸”
                if data_flow.get('input_fields'):
                    input_table = Table(title="ğŸ“¥ ì…ë ¥ í•„ë“œ", show_header=True, header_style="bold blue")
                    input_table.add_column("í•„ë“œëª…")
                    input_table.add_column("íƒ€ì…")
                    input_table.add_column("í•„ìˆ˜ì—¬ë¶€")
                    input_table.add_column("ì„¤ëª…")
                    
                    for field in data_flow['input_fields']:
                        required_text = "âœ“" if field.get('required', False) else "âœ—"
                        input_table.add_row(
                            field.get('name', 'N/A'),
                            field.get('type', 'N/A'),
                            required_text,
                            field.get('description', 'N/A')
                        )
                    tables.append(input_table)
                
                # ì¶œë ¥ í•„ë“œ í…Œì´ë¸”
                if data_flow.get('output_fields'):
                    output_table = Table(title="ğŸ“¤ ì¶œë ¥ í•„ë“œ", show_header=True, header_style="bold green")
                    output_table.add_column("í•„ë“œëª…")
                    output_table.add_column("íƒ€ì…")
                    output_table.add_column("ì„¤ëª…")
                    
                    for field in data_flow['output_fields']:
                        output_table.add_row(
                            field.get('name', 'N/A'),
                            field.get('type', 'N/A'),
                            field.get('description', 'N/A')
                        )
                    tables.append(output_table)
                    
        # SQL íŒŒì¼ íŠ¹í™” í…Œì´ë¸”ë“¤
        elif file_path.endswith('.sql'):
            # ì…ì¶œë ¥ ë¶„ì„ í…Œì´ë¸”
            if 'input_output_analysis' in llm_analysis:
                io_analysis = llm_analysis['input_output_analysis']
                
                # ë°”ì¸ë“œ ë³€ìˆ˜ í…Œì´ë¸”
                if io_analysis.get('inputs'):
                    input_table = Table(title="ğŸ“¥ ë°”ì¸ë“œ ë³€ìˆ˜", show_header=True, header_style="bold blue")
                    input_table.add_column("ë³€ìˆ˜ëª…")
                    input_table.add_column("íƒ€ì…") 
                    input_table.add_column("Nullable")
                    input_table.add_column("ì„¤ëª…")
                    input_table.add_column("ì˜ˆì‹œ")
                    
                    for inp in io_analysis['inputs']:
                        nullable_text = "O" if inp.get('nullable', False) else "X"
                        input_table.add_row(
                            inp.get('name', 'N/A'),
                            inp.get('type', 'N/A'),
                            nullable_text,
                            inp.get('description', 'N/A'),
                            inp.get('example', 'N/A')
                        )
                    tables.append(input_table)
                
                # ì¶œë ¥ ì»¬ëŸ¼ í…Œì´ë¸”
                if io_analysis.get('outputs'):
                    output_table = Table(title="ğŸ“¤ ì¶œë ¥ ì»¬ëŸ¼", show_header=True, header_style="bold green")
                    output_table.add_column("ì»¬ëŸ¼ëª…")
                    output_table.add_column("íƒ€ì…")
                    output_table.add_column("ì„¤ëª…")
                    output_table.add_column("ì¶œì²˜ í…Œì´ë¸”")
                    
                    for out in io_analysis['outputs']:
                        output_table.add_row(
                            out.get('name', 'N/A'),
                            out.get('type', 'N/A'),
                            out.get('description', 'N/A'),
                            out.get('table_source', 'N/A')
                        )
                    tables.append(output_table)
            
            # í…Œì´ë¸” ì¡°ì¸ ë¶„ì„ í…Œì´ë¸”
            if 'table_analysis' in llm_analysis and llm_analysis['table_analysis'].get('join_analysis'):
                join_table = Table(title="ğŸ”— í…Œì´ë¸” ì¡°ì¸ ë¶„ì„", show_header=True, header_style="bold cyan")
                join_table.add_column("ì¡°ì¸ íƒ€ì…")
                join_table.add_column("í…Œì´ë¸”ë“¤")
                join_table.add_column("ì¡°ì¸ ì¡°ê±´")
                join_table.add_column("ëª©ì ")
                
                for join in llm_analysis['table_analysis']['join_analysis']:
                    tables_str = " â†” ".join(join.get('tables', []))
                    join_table.add_row(
                        join.get('type', 'N/A'),
                        tables_str,
                        join.get('condition', 'N/A'),
                        join.get('purpose', 'N/A')
                    )
                tables.append(join_table)
                
        # ê¸°ë³¸ ì…ì¶œë ¥ í…Œì´ë¸” (ë‹¤ë¥¸ íŒŒì¼ íƒ€ì…ë“¤)
        else:
            if 'input_output_analysis' in llm_analysis:
                io_analysis = llm_analysis['input_output_analysis']
                
                # ì…ë ¥ íŒŒë¼ë¯¸í„° í…Œì´ë¸”
                if io_analysis.get('inputs'):
                    input_table = Table(title="ğŸ“¥ ì…ë ¥ íŒŒë¼ë¯¸í„°", show_header=True, header_style="bold blue")
                    input_table.add_column("íŒŒë¼ë¯¸í„°ëª…")
                    input_table.add_column("íƒ€ì…") 
                    input_table.add_column("Nullable")
                    input_table.add_column("ì„¤ëª…")
                    
                    for inp in io_analysis['inputs']:
                        nullable_text = "O" if inp.get('nullable', False) else "X"
                        input_table.add_row(
                            inp.get('name', 'N/A'),
                            inp.get('type', 'N/A'),
                            nullable_text,
                            inp.get('description', 'N/A')
                        )
                    tables.append(input_table)
                
                # ì¶œë ¥ ê°’ í…Œì´ë¸”
                if io_analysis.get('outputs'):
                    output_table = Table(title="ğŸ“¤ ì¶œë ¥ ê°’", show_header=True, header_style="bold green")
                    output_table.add_column("ì¶œë ¥ê°’ëª…")
                    output_table.add_column("íƒ€ì…")
                    output_table.add_column("ì„¤ëª…")
                    
                    for out in io_analysis['outputs']:
                        output_table.add_row(
                            out.get('name', 'N/A'),
                            out.get('type', 'N/A'),
                            out.get('description', 'N/A')
                        )
                    tables.append(output_table)
        
        return tables

    def _display_detailed_analysis(self, files_data: Dict):
        """íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„ í‘œì‹œ"""
        if not files_data:
            return
            
        self.console.print("\n[bold blue]ğŸ“‹ íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„[/bold blue]")
        
        for file_path, file_info in files_data.items():
            filename = os.path.basename(file_path)
            llm_analysis = file_info.get('llm_analysis', {})
            
            if llm_analysis and 'purpose' in llm_analysis:
                # LLM ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
                content = f"**ëª©ì **: {llm_analysis.get('purpose', 'N/A')}\n\n"
                
                
                if 'key_functions' in llm_analysis and llm_analysis['key_functions']:
                    if isinstance(llm_analysis['key_functions'], list):
                        # ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì´ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                        func_strs = []
                        for func in llm_analysis['key_functions']:
                            if isinstance(func, dict):
                                func_strs.append(str(func.get('name', func)))
                            else:
                                func_strs.append(str(func))
                        content += f"**ì£¼ìš” í•¨ìˆ˜**: {', '.join(func_strs)}\n\n"
                    else:
                        content += f"**ì£¼ìš” í•¨ìˆ˜**: {llm_analysis['key_functions']}\n\n"
                
                # íŒŒì¼ íƒ€ì…ë³„ íŠ¹í™”ëœ í…Œì´ë¸” ìƒì„±
                special_tables = self._create_file_type_tables(llm_analysis, file_path)
                
                
                panel = Panel(
                    Markdown(content.strip()),
                    title=f"ğŸ“„ {filename}",
                    border_style="green"
                )
                self.console.print(panel)
                
                # íŒŒì¼ íƒ€ì…ë³„ íŠ¹í™” í…Œì´ë¸”ë“¤ì„ ë³„ë„ë¡œ í‘œì‹œ
                for table in special_tables:
                    self.console.print(table)
                    self.console.print()  # ë¹ˆ ì¤„ ì¶”ê°€
                    
            else:
                # ê¸°ë³¸ ë¶„ì„ë§Œ ìˆëŠ” ê²½ìš°
                basic_analysis = file_info.get('basic_analysis', {})
                content = f"íŒŒì¼ íƒ€ì…: {file_info.get('file_type', 'unknown')}\n"
                content += f"ê¸°ë³¸ ë¶„ì„: {str(basic_analysis)[:200]}..."
                
                panel = Panel(
                    content,
                    title=f"ğŸ“„ {filename}",
                    border_style="yellow"
                )
                self.console.print(panel)

    def _display_call_graph(self, call_graph: Dict):
        """í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ í‘œì‹œ"""
        if not call_graph:
            return
            
        self.console.print("\n[bold purple]ğŸ”— í˜¸ì¶œ ê´€ê³„ ë¶„ì„[/bold purple]")
        
        for file_path, calls in call_graph.items():
            filename = os.path.basename(file_path)
            if calls:
                self.console.print(f"ğŸ“„ {filename}:")
                for call in calls:
                    self.console.print(f"  â†’ {call}")