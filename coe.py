#!/usr/bin/env python3
"""
Swing CLIì˜ ë…ë¦½ ì‹¤í–‰ ëª…ë ¹ì–´ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤.
Usage: python coe.py [command] [options]
"""

import sys
import os
import click
from typing import Dict, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
sys.path.insert(0, os.path.abspath(os.path.dirname(__file__)))

from actions.file_manager import FileManager
from llm.service import LLMService
from rich.console import Console
from rich.panel import Panel
from rich.table import Table
from rich.tree import Tree
from rich.text import Text
from rich.columns import Columns
from rich.markdown import Markdown


class CoeAnalyzer:
    def __init__(self):
        self.file_manager = FileManager()
        self.llm_service = LLMService()
        self.console = Console()

    def analyze_files(self, file_paths: List[str], use_llm: bool = True) -> Dict:
        """íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ê³  ê²°ê³¼ë¥¼ ë°˜í™˜"""
        analysis_results = {
            'files': {},
            'summary': {},
            'call_graph': {},
            'file_categories': {}
        }
        
        # íŒŒì¼ë“¤ ì¶”ê°€ ë° ê¸°ë³¸ ë¶„ì„
        self.console.print("[bold blue]ğŸ“ íŒŒì¼ë“¤ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...[/bold blue]")
        
        for file_path in file_paths:
            if os.path.exists(file_path):
                result = self.file_manager.add_single_file(file_path)
                if result['analysis']:
                    analysis_results['files'][file_path] = {
                        'file_type': result['file_type'],
                        'basic_analysis': result['analysis'],
                        'llm_analysis': None
                    }
        
        # LLM ê¸°ë°˜ ë¶„ì„
        if use_llm and analysis_results['files']:
            self.console.print("[bold blue]ğŸ§  LLMì„ í†µí•œ ì‹¬í™” ë¶„ì„ì„ ìˆ˜í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤...[/bold blue]")
            llm_analysis = self._perform_llm_analysis(analysis_results['files'])
            
            # LLM ë¶„ì„ ê²°ê³¼ë¥¼ í†µí•©
            for file_path, llm_result in llm_analysis.items():
                if file_path in analysis_results['files']:
                    analysis_results['files'][file_path]['llm_analysis'] = llm_result
            
            # ì „ì²´ ìš”ì•½ ìƒì„±
            analysis_results['summary'] = self._generate_summary(analysis_results['files'])
            analysis_results['call_graph'] = self._extract_call_relationships(analysis_results['files'])
            analysis_results['file_categories'] = self._categorize_files(analysis_results['files'])
        
        return analysis_results

    def _perform_llm_analysis(self, files_data: Dict) -> Dict:
        """LLMì„ í†µí•œ íŒŒì¼ ë¶„ì„"""
        llm_results = {}
        
        self.console.print(f"[dim]DEBUG: _perform_llm_analysis ì‹œì‘, íŒŒì¼ ìˆ˜: {len(files_data)}[/dim]")
        
        for file_path, file_info in files_data.items():
            try:
                self.console.print(f"[dim]DEBUG: íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path}[/dim]")
                
                # íŒŒì¼ ë‚´ìš© ê°€ì ¸ì˜¤ê¸°
                content = self.file_manager.files.get(file_path, "")
                self.console.print(f"[dim]DEBUG: íŒŒì¼ ë‚´ìš© ê¸¸ì´: {len(content)}[/dim]")
                
                if not content:
                    self.console.print(f"[dim]DEBUG: íŒŒì¼ ë‚´ìš©ì´ ë¹„ì–´ìˆì–´ ê±´ë„ˆëœ€: {file_path}[/dim]")
                    continue
                
                # LLM ë¶„ì„ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
                analysis_prompt = self._build_analysis_prompt(file_path, file_info, content)
                self.console.print(f"[dim]DEBUG: í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(analysis_prompt)}[/dim]")
                
                # LLM í˜¸ì¶œ
                messages = [
                    {"role": "system", "content": "You are a code analysis expert. Analyze the given file and provide structured insights."},
                    {"role": "user", "content": analysis_prompt}
                ]
                
                self.console.print(f"[dim]DEBUG: LLM í˜¸ì¶œ ì‹œì‘[/dim]")
                response = self.llm_service.chat_completion(messages)
                
                if response and "choices" in response:
                    llm_content = response["choices"][0]["message"]["content"]
                    self.console.print(f"[dim]DEBUG: LLM ì‘ë‹µ ê¸¸ì´: {len(llm_content)}[/dim]")
                    self.console.print(f"[dim]DEBUG: LLM ì‘ë‹µ ë¯¸ë¦¬ë³´ê¸°: {llm_content[:200]}...[/dim]")
                    
                    parsed_result = self._parse_llm_response(llm_content)
                    self.console.print(f"[dim]DEBUG: íŒŒì‹± ê²°ê³¼ í‚¤ë“¤: {list(parsed_result.keys()) if isinstance(parsed_result, dict) else 'not dict'}[/dim]")
                    
                    llm_results[file_path] = parsed_result
                else:
                    self.console.print(f"[dim]DEBUG: LLM ì‘ë‹µì´ ë¹„ì–´ìˆìŒ ë˜ëŠ” í˜•ì‹ ì˜¤ë¥˜[/dim]")
                
            except Exception as e:
                self.console.print(f"[red]LLM ë¶„ì„ ì‹¤íŒ¨ ({file_path}): {e}[/red]")
                import traceback
                self.console.print(f"[dim]{traceback.format_exc()}[/dim]")
                continue
        
        self.console.print(f"[dim]DEBUG: _perform_llm_analysis ì™„ë£Œ, ê²°ê³¼ ìˆ˜: {len(llm_results)}[/dim]")
        return llm_results

    def _build_analysis_prompt(self, file_path: str, file_info: Dict, content: str) -> str:
        """LLM ë¶„ì„ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        file_type = file_info.get('file_type', 'unknown')
        basic_analysis = file_info.get('basic_analysis', {})
        
        prompt = f"""íŒŒì¼ ë¶„ì„ ìš”ì²­:

íŒŒì¼ ê²½ë¡œ: {file_path}
íŒŒì¼ íƒ€ì…: {file_type}

ê¸°ë³¸ ë¶„ì„ ê²°ê³¼:
{str(basic_analysis)}

íŒŒì¼ ë‚´ìš©:
```
{content[:3000]}{'...' if len(content) > 3000 else ''}
```

ë‹¤ìŒ í•­ëª©ë“¤ì„ JSON í˜•íƒœë¡œ ì •í™•íˆ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. purpose: íŒŒì¼ì˜ ì£¼ìš” ëª©ì ê³¼ ì—­í•  (í•œêµ­ì–´ë¡œ ìƒì„¸íˆ)
2. key_functions: ì£¼ìš” í•¨ìˆ˜ë“¤ê³¼ ê·¸ ì—­í•  ë¦¬ìŠ¤íŠ¸
3. input_output_analysis: {{
   "inputs": [
     {{
       "name": "íŒŒë¼ë¯¸í„°ëª…",
       "type": "ë°ì´í„°íƒ€ì…", 
       "nullable": true/false,
       "description": "íŒŒë¼ë¯¸í„° ì„¤ëª…"
     }}
   ],
   "outputs": [
     {{
       "name": "ë¦¬í„´ê°’ëª…",
       "type": "ë°ì´í„°íƒ€ì…",
       "nullable": true/false, 
       "description": "ë¦¬í„´ê°’ ì„¤ëª…"
     }}
   ]
}}
4. dependencies: ì˜ì¡´ì„± ë¶„ì„ (imports, includes ë“±)
5. complexity_score: ë³µì¡ë„ ì ìˆ˜ (1-10)
6. maintainability: ìœ ì§€ë³´ìˆ˜ì„± í‰ê°€ (í•œêµ­ì–´)
7. suggestions: ê°œì„  ì œì•ˆì‚¬í•­ (í•œêµ­ì–´)
8. call_patterns: í˜¸ì¶œ ê´€ê³„ íŒ¨í„´

**ì¤‘ìš”**: 
- input_output_analysisì—ì„œ nullable ì •ë³´ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•˜ì„¸ìš”
- C í•¨ìˆ˜ì˜ í¬ì¸í„° íŒŒë¼ë¯¸í„°ëŠ” nullable: trueë¡œ ì„¤ì •
- SQLì˜ ë°”ì¸ë“œ ë³€ìˆ˜ëŠ” nullable ì—¬ë¶€ë¥¼ ëª…ì‹œí•˜ì„¸ìš”
- ëª¨ë“  ì…ì¶œë ¥ ê°’ì— ëŒ€í•´ nullable ì •ë³´ë¥¼ ë¹ ì§ì—†ì´ ì œê³µí•˜ì„¸ìš”

JSON í˜•íƒœë¡œë§Œ ì‘ë‹µí•˜ê³ , ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”."""
        
        return prompt

    def _parse_llm_response(self, llm_content: str) -> Dict:
        """LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜"""
        try:
            import json
            # JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
            if '```json' in llm_content:
                start = llm_content.find('```json') + 7
                end = llm_content.find('```', start)
                json_str = llm_content[start:end].strip()
            elif llm_content.strip().startswith('{'):
                json_str = llm_content.strip()
            else:
                # JSONì´ ì•„ë‹Œ ê²½ìš° ê¸°ë³¸ êµ¬ì¡°ë¡œ ë³€í™˜
                return {
                    'purpose': 'LLM ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨',
                    'raw_response': llm_content
                }
            
            return json.loads(json_str)
        except Exception as e:
            return {
                'purpose': 'LLM ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨',
                'error': str(e),
                'raw_response': llm_content
            }

    def _generate_summary(self, files_data: Dict) -> Dict:
        """ì „ì²´ íŒŒì¼ë“¤ì˜ ìš”ì•½ ìƒì„±"""
        summary = {
            'total_files': len(files_data),
            'file_types': {},
            'complexity_overview': {},
            'common_patterns': []
        }
        
        # íŒŒì¼ íƒ€ì…ë³„ í†µê³„
        for file_path, file_info in files_data.items():
            file_type = file_info.get('file_type', 'unknown')
            if file_type not in summary['file_types']:
                summary['file_types'][file_type] = 0
            summary['file_types'][file_type] += 1
        
        # ë³µì¡ë„ ë¶„ì„
        complexities = []
        for file_path, file_info in files_data.items():
            llm_analysis = file_info.get('llm_analysis', {})
            if llm_analysis and 'complexity_score' in llm_analysis:
                complexities.append(llm_analysis['complexity_score'])
        
        if complexities:
            summary['complexity_overview'] = {
                'average': sum(complexities) / len(complexities),
                'max': max(complexities),
                'min': min(complexities)
            }
        
        return summary

    def _extract_call_relationships(self, files_data: Dict) -> Dict:
        """í˜¸ì¶œ ê´€ê³„ ë¶„ì„"""
        call_graph = {}
        
        for file_path, file_info in files_data.items():
            llm_analysis = file_info.get('llm_analysis', {})
            if llm_analysis and 'call_patterns' in llm_analysis:
                call_graph[file_path] = llm_analysis['call_patterns']
        
        return call_graph

    def _categorize_files(self, files_data: Dict) -> Dict:
        """íŒŒì¼ë“¤ì„ ì¹´í…Œê³ ë¦¬ë³„ë¡œ ë¶„ë¥˜"""
        categories = {
            'controller': [],
            'utils': [],
            'service': [],
            'sql': [],
            'config': [],
            'ui': [],
            'other': []
        }
        
        for file_path, file_info in files_data.items():
            llm_analysis = file_info.get('llm_analysis', {})
            file_type = file_info.get('file_type', 'unknown')
            
            # íŒŒì¼ëª…ê³¼ ë‚´ìš© ê¸°ë°˜ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ ê²°ì •
            filename = os.path.basename(file_path).lower()
            
            if file_type == 'sql_file' or filename.endswith('.sql'):
                categories['sql'].append(file_path)
            elif any(keyword in filename for keyword in ['main', 'controller', 'ctrl']):
                categories['controller'].append(file_path)
            elif any(keyword in filename for keyword in ['util', 'helper', 'tool']):
                categories['utils'].append(file_path)
            elif any(keyword in filename for keyword in ['service', 'svc']):
                categories['service'].append(file_path)
            elif any(keyword in filename for keyword in ['config', 'setting']):
                categories['config'].append(file_path)
            elif file_type == 'xml_file' or filename.endswith('.xml'):
                categories['ui'].append(file_path)
            else:
                categories['other'].append(file_path)
        
        return categories

    def display_analysis_results(self, results: Dict):
        """ë¶„ì„ ê²°ê³¼ë¥¼ Rich UIë¡œ í‘œì‹œ"""
        self.console.print("\n[bold green]ğŸ¯ ì½”ë“œ êµ¬ì¡° ë¶„ì„ ê²°ê³¼[/bold green]")
        
        # 1. ì „ì²´ ìš”ì•½
        self._display_summary(results['summary'])
        
        # 2. íŒŒì¼ ì¹´í…Œê³ ë¦¬
        self._display_file_categories(results['file_categories'])
        
        # 3. íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„
        self._display_detailed_analysis(results['files'])
        
        # 4. í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„
        if results['call_graph']:
            self._display_call_graph(results['call_graph'])

    def _display_summary(self, summary: Dict):
        """ì „ì²´ ìš”ì•½ í‘œì‹œ"""
        if not summary:
            return
            
        # ìš”ì•½ íŒ¨ë„
        summary_text = f"ë¶„ì„ëœ íŒŒì¼ ìˆ˜: {summary.get('total_files', 0)}ê°œ\n"
        
        file_types = summary.get('file_types', {})
        if file_types:
            summary_text += "\níŒŒì¼ íƒ€ì…ë³„ ë¶„í¬:\n"
            for file_type, count in file_types.items():
                summary_text += f"  â€¢ {file_type}: {count}ê°œ\n"
        
        complexity = summary.get('complexity_overview', {})
        if complexity:
            summary_text += f"\në³µì¡ë„ ë¶„ì„:\n"
            summary_text += f"  â€¢ í‰ê· : {complexity.get('average', 0):.1f}/10\n"
            summary_text += f"  â€¢ ìµœê³ : {complexity.get('max', 0)}/10\n"
            summary_text += f"  â€¢ ìµœì €: {complexity.get('min', 0)}/10\n"
        
        panel = Panel(
            summary_text.strip(),
            title="ğŸ“Š ì „ì²´ ìš”ì•½",
            border_style="blue"
        )
        self.console.print(panel)

    def _display_file_categories(self, categories: Dict):
        """íŒŒì¼ ì¹´í…Œê³ ë¦¬ í‘œì‹œ"""
        if not categories:
            return
            
        tree = Tree("ğŸ“ íŒŒì¼ ì¹´í…Œê³ ë¦¬")
        
        for category, files in categories.items():
            if files:
                category_node = tree.add(f"[bold]{category.upper()}[/bold] ({len(files)}ê°œ)")
                for file_path in files:
                    filename = os.path.basename(file_path)
                    category_node.add(f"ğŸ“„ {filename}")
        
        self.console.print(tree)

    def _display_detailed_analysis(self, files_data: Dict):
        """íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„ í‘œì‹œ"""
        if not files_data:
            return
            
        self.console.print("\n[bold blue]ğŸ“‹ íŒŒì¼ë³„ ìƒì„¸ ë¶„ì„[/bold blue]")
        
        for file_path, file_info in files_data.items():
            filename = os.path.basename(file_path)
            llm_analysis = file_info.get('llm_analysis', {})
            
            if llm_analysis and 'purpose' in llm_analysis:
                # LLM ë¶„ì„ ê²°ê³¼ê°€ ìˆëŠ” ê²½ìš°
                content = f"**ëª©ì **: {llm_analysis.get('purpose', 'N/A')}\n\n"
                
                if 'complexity_score' in llm_analysis:
                    content += f"**ë³µì¡ë„**: {llm_analysis['complexity_score']}/10\n\n"
                
                if 'key_functions' in llm_analysis and llm_analysis['key_functions']:
                    if isinstance(llm_analysis['key_functions'], list):
                        # ë¦¬ìŠ¤íŠ¸ì˜ ê° í•­ëª©ì´ ë¬¸ìì—´ì¸ì§€ í™•ì¸
                        func_strs = []
                        for func in llm_analysis['key_functions']:
                            if isinstance(func, dict):
                                func_strs.append(str(func.get('name', func)))
                            else:
                                func_strs.append(str(func))
                        content += f"**ì£¼ìš” í•¨ìˆ˜**: {', '.join(func_strs)}\n\n"
                    else:
                        content += f"**ì£¼ìš” í•¨ìˆ˜**: {llm_analysis['key_functions']}\n\n"
                
                # Input/Output ë¶„ì„ ì¶”ê°€
                if 'input_output_analysis' in llm_analysis:
                    io_analysis = llm_analysis['input_output_analysis']
                    if io_analysis:
                        content += "**ğŸ“¥ ì…ë ¥ íŒŒë¼ë¯¸í„°**:\n"
                        inputs = io_analysis.get('inputs', [])
                        if inputs:
                            for inp in inputs:
                                nullable_text = " (nullable)" if inp.get('nullable', False) else " (non-null)"
                                content += f"  â€¢ {inp.get('name', 'N/A')} ({inp.get('type', 'N/A')}){nullable_text}: {inp.get('description', 'N/A')}\n"
                        else:
                            content += "  â€¢ ì—†ìŒ\n"
                        
                        content += "\n**ğŸ“¤ ì¶œë ¥ ê°’**:\n"
                        outputs = io_analysis.get('outputs', [])
                        if outputs:
                            for out in outputs:
                                nullable_text = " (nullable)" if out.get('nullable', False) else " (non-null)"
                                content += f"  â€¢ {out.get('name', 'N/A')} ({out.get('type', 'N/A')}){nullable_text}: {out.get('description', 'N/A')}\n"
                        else:
                            content += "  â€¢ ì—†ìŒ\n"
                        content += "\n"
                
                if 'maintainability' in llm_analysis and llm_analysis['maintainability']:
                    content += f"**ìœ ì§€ë³´ìˆ˜ì„±**: {llm_analysis['maintainability']}\n\n"
                
                if 'suggestions' in llm_analysis and llm_analysis['suggestions']:
                    content += f"**ê°œì„ ì‚¬í•­**: {llm_analysis['suggestions']}\n\n"
                
                panel = Panel(
                    Markdown(content.strip()),
                    title=f"ğŸ“„ {filename}",
                    border_style="green"
                )
            else:
                # ê¸°ë³¸ ë¶„ì„ë§Œ ìˆëŠ” ê²½ìš°
                basic_analysis = file_info.get('basic_analysis', {})
                content = f"íŒŒì¼ íƒ€ì…: {file_info.get('file_type', 'unknown')}\n"
                content += f"ê¸°ë³¸ ë¶„ì„: {str(basic_analysis)[:200]}..."
                
                panel = Panel(
                    content,
                    title=f"ğŸ“„ {filename}",
                    border_style="yellow"
                )
            
            self.console.print(panel)

    def _display_call_graph(self, call_graph: Dict):
        """í˜¸ì¶œ ê´€ê³„ ê·¸ë˜í”„ í‘œì‹œ"""
        if not call_graph:
            return
            
        self.console.print("\n[bold purple]ğŸ”— í˜¸ì¶œ ê´€ê³„ ë¶„ì„[/bold purple]")
        
        tree = Tree("í˜¸ì¶œ ê´€ê³„")
        for file_path, patterns in call_graph.items():
            filename = os.path.basename(file_path)
            if patterns:
                file_node = tree.add(f"ğŸ“„ {filename}")
                if isinstance(patterns, list):
                    for pattern in patterns:
                        file_node.add(f"â†’ {pattern}")
                elif isinstance(patterns, str):
                    file_node.add(f"â†’ {patterns}")
        
        self.console.print(tree)


@click.group()
def cli():
    """Swing CLI ë„êµ¬ - ì½”ë“œ ë¶„ì„ ë° ê´€ë¦¬"""
    pass


@cli.command()
@click.argument('files', nargs=-1, type=click.Path(exists=True))
@click.option('--no-llm', is_flag=True, help='LLM ë¶„ì„ ì—†ì´ ê¸°ë³¸ ë¶„ì„ë§Œ ìˆ˜í–‰')
@click.option('--output', '-o', help='ë¶„ì„ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥')
def analyze(files, no_llm, output):
    """íŒŒì¼ë“¤ì˜ ì½”ë“œ êµ¬ì¡°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.
    
    Usage:
        coe analyze file1.c file2.sql
        coe analyze src/ --no-llm
        coe analyze *.c -o analysis_result.json
    """
    if not files:
        console = Console()
        console.print("[red]ë¶„ì„í•  íŒŒì¼ì„ ì§€ì •í•´ì£¼ì„¸ìš”.[/red]")
        console.print("ì‚¬ìš©ë²•: coe analyze <file1> <file2> ...")
        return
    
    analyzer = CoeAnalyzer()
    
    # íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ì²˜ë¦¬
    file_list = []
    for file_path in files:
        if os.path.isdir(file_path):
            # ë””ë ‰í† ë¦¬ì¸ ê²½ìš° í•˜ìœ„ íŒŒì¼ë“¤ ìˆ˜ì§‘
            for root, dirs, filenames in os.walk(file_path):
                for filename in filenames:
                    if filename.endswith(('.c', '.h', '.sql', '.xml', '.py')):
                        file_list.append(os.path.join(root, filename))
        else:
            file_list.append(file_path)
    
    # ë¶„ì„ ìˆ˜í–‰
    use_llm = not no_llm
    results = analyzer.analyze_files(file_list, use_llm=use_llm)
    
    # ê²°ê³¼ í‘œì‹œ
    analyzer.display_analysis_results(results)
    
    # íŒŒì¼ë¡œ ì €ì¥ (ì„ íƒì‚¬í•­)
    if output:
        import json
        with open(output, 'w', encoding='utf-8') as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        analyzer.console.print(f"\n[green]ë¶„ì„ ê²°ê³¼ê°€ {output}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.[/green]")


@cli.command()
def version():
    """ë²„ì „ ì •ë³´ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤."""
    console = Console()
    console.print("[bold green]Swing CLI v0.2.0[/bold green]")
    console.print("ğŸŒ€ ì½”ë“œ êµ¬ì¡° ë¶„ì„ ë° ëŒ€í™”í˜• CLI ë„êµ¬")


if __name__ == '__main__':
    cli()